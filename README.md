# LG-Urban

**AI-powered urban data analysis platform for Bologna with sandboxed Python execution.**

Built on LangGraph, this production-ready application combines conversational AI with secure code execution, civic dataset integration, and geographic visualization tools.

---

## ðŸŽ¯ Core Features

### ðŸ’¬ Intelligent Conversations
- Multi-threaded chat with streaming responses
- Automatic context summarization (configurable window per thread)
- PostgreSQL-backed persistence with full message history
- Per-thread LLM configuration (model, temperature, system prompt)

### ðŸ Sandboxed Code Execution
- Isolated Docker containers with 15+ data science libraries
- Persistent variables across executions within a thread
- Automatic artifact ingestion with SHA-256 deduplication
- Pre-installed: pandas, numpy, matplotlib, seaborn, scikit-learn, geopandas, folium

### ðŸ“Š Bologna OpenData Integration
- **6 API tools** for civic dataset discovery:
  - `list_catalog` - Search 100+ public datasets by keyword
  - `preview_dataset` - Preview first rows
  - `get_dataset_description` - Metadata and descriptions
  - `get_dataset_fields` - Field definitions
  - `is_geo_dataset` - Check for geographic data
  - `get_dataset_time_info` - Temporal coverage

### ðŸ—ºï¸ Geographic Visualization
- **Ortofoto Tools**: View and compare aerial photographs (2012-2023)
- **3D City Model**: Interactive 3D visualization of Bologna
- **Folium Integration**: Dynamic map generation with overlays
- **GeoParquet Support**: Native handling of geographic datasets

### ðŸ“ S3-based Dataset Management

### ðŸŽ¨ Modern UI
- React + TypeScript frontend with dark mode
- Real-time SSE streaming with tool execution visibility
- Inline artifact display (images, HTML maps, tables)
- Responsive design with TailwindCSS

---

## ðŸš€ Quick Start

1. Start RDS tunnel
```bash
~/start-rds-tunnel.sh
```
### 2. Set env vars (create .env in project root)

### 3. Run backend
```bash
cd ~/LG-Urban
uvicorn backend.main:app --reload --port 8000
```
### 4. Run frontend (separate terminal)
```bash
cd frontend
npm run dev
```

Below the older startup method with compose (we trashing that)

### Prerequisites
- Docker & Docker Compose
- OpenAI API key (required)
- Tavily API key (optional, for web search)
- Google Maps API key (optional, for geocoding)

### 1. Setup

```bash
# Clone or navigate to project
cd LG-Urban

# Create environment file
cat > .env << EOF
OPENAI_API_KEY=your_key_here
TAVILY_API_KEY=your_tavily_key  # optional
GOOGLE_MAPS_API_KEY=your_google_key  # optional

DEFAULT_MODEL=gpt-4o
DEFAULT_TEMPERATURE=0.7
CONTEXT_WINDOW=30000

DATASET_ACCESS=API
EOF

# Create Docker network
docker network create langgraph-network
```

### 2. Build Sandbox Image

```bash
docker build -f Dockerfile.sandbox -t sandbox:latest .
```

### 3. Start Application

```bash
docker compose up -d
```

Services will start:
- **Frontend**: http://localhost (port 80)
- **Backend API**: http://localhost:8000
- **Database Admin**: http://localhost:8080 (Adminer)
- **PostgreSQL**: port 5432

### 4. Access

Open http://localhost in your browser and start chatting!

---

## ðŸ“– Usage Examples

### Data Analysis
```
"Show me active tattoo studios in Bologna and suggest where to open a new one"
â†’ Fetches elenco-esercizi dataset, filters by activity type, creates geographic heatmap
```

### Geographic Visualization
```
"Compare Giardini Margherita in 2017 and 2023"
â†’ Creates side-by-side ortofoto comparison map
```

### Custom Visualizations
```
"Load the bike-sharing dataset and create a time series of daily usage"
â†’ Fetches dataset, analyzes temporal patterns, generates matplotlib plot
```

---

## ðŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  React UI   â”‚  (SSE streaming, artifact display)
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚ HTTP/SSE
â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  FastAPI Backend                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  LangGraph Agent         â”‚   â”‚
â”‚  â”‚  â”œâ”€ Internet Search      â”‚   â”‚
â”‚  â”‚  â”œâ”€ Code Sandbox         â”‚â—„â”€â”€â”¼â”€â”€â”€ Docker containers
â”‚  â”‚  â”œâ”€ Bologna OpenData API â”‚   â”‚
â”‚  â”‚  â”œâ”€ Datasets Management  â”‚   â”‚
â”‚  â”‚  â””â”€ Geographic Tools     â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
      â”‚        â”‚          â”‚
  â”Œâ”€â”€â”€â–¼â”€â”€â”  â”Œâ”€â”€â–¼â”€â”€â”€â”€â”€â”  â”Œâ”€â–¼â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ PG   â”‚  â”‚  PG    â”‚  â”‚Blobstoreâ”‚
  â”‚ DB   â”‚  â”‚Checkpt â”‚  â”‚ (files) â”‚
  â””â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Storage Strategy

| Store | Contents | Purpose |
|-------|----------|---------|
| **PostgreSQL** | Threads, messages, configs, artifact metadata | Source of truth, queryable, relational |
| **PostgreSQL** | LangGraph checkpoints, agent state | Persistent, concurrent, scalable |
| **Blobstore** | Artifact bytes (images, CSVs, maps) | Content-addressed, deduplicated, scalable |

---

## âš™ï¸ Configuration

### Environment Variables

| Variable | Default | Description |
|----------|---------|-------------|
| `OPENAI_API_KEY` | *(required)* | OpenAI API key |
| `DEFAULT_MODEL` | `gpt-4o` | LLM model name |
| `DEFAULT_TEMPERATURE` | `0.7` | Sampling temperature |
| `CONTEXT_WINDOW` | `30000` | Max tokens before summarization |
| `DATASET_ACCESS` | `API` | Dataset mode: `NONE`, `API`, `LOCAL_RO`, `HYBRID` |
| `SESSION_STORAGE` | `TMPFS` | Sandbox storage: `TMPFS` (RAM) or `BIND` (disk) |
| `MAX_ARTIFACT_SIZE_MB` | `50` | Max file size per artifact |
| `CORS_ORIGINS` | `http://localhost,http://localhost:80` | Allowed origins |

### Dataset Access Modes

| Mode | Description | Use Case |
|------|-------------|----------|
| `NONE` | No datasets | Basic Python sandbox |
| `API` | Fetch from Bologna OpenData API | Default, flexible |
| `LOCAL_RO` | Mount local datasets read-only | Heavy/offline datasets |
| `HYBRID` | API + local heavy datasets | Best of both |

---

## ðŸ› ï¸ Development

### Local Development (without Docker)

**Backend:**
```bash
# Install dependencies
pip install -r requirements.txt

# Start PostgreSQL
docker compose up -d db

# Run migrations
docker exec lg_urban_backend alembic upgrade head

# Start backend
uvicorn backend.main:app --reload --port 8000
```

**Frontend:**
```bash
cd frontend
npm install
npm run dev  # http://localhost:5173
```

### Database Migrations

```bash
# Check current version
docker exec lg_urban_backend alembic current

# Apply migrations
docker exec lg_urban_backend alembic upgrade head

# Create new migration
docker exec lg_urban_backend alembic revision --autogenerate -m "description"
```

See [DB-README.md](./DB-README.md) for detailed database documentation.

---

## ðŸ“‚ Project Structure

```
LG-Urban/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app/              # API routes (threads, messages)
â”‚   â”œâ”€â”€ db/               # SQLAlchemy models, Alembic migrations
â”‚   â”œâ”€â”€ graph/            # LangGraph agent, tools, prompts
â”‚   â”œâ”€â”€ sandbox/          # Docker sandbox manager
â”‚   â”œâ”€â”€ artifacts/        # Blobstore storage & ingestion
â”‚   â”œâ”€â”€ opendata_api/     # Bologna OpenData client
â”‚   â”œâ”€â”€ dataset_manager/  # Dataset download & caching
â”‚   â””â”€â”€ tool_factory/     # LangChain tool creation
â”œâ”€â”€ frontend/
â”‚   â””â”€â”€ src/
â”‚       â”œâ”€â”€ components/   # React UI (MessageList, ArtifactCard, etc.)
â”‚       â”œâ”€â”€ hooks/        # SSE streaming, API calls
â”‚       â”œâ”€â”€ store/        # Zustand state management
â”‚       â””â”€â”€ types/        # TypeScript definitions
â”œâ”€â”€ docker-compose.yml    # Full stack orchestration
â”œâ”€â”€ Dockerfile.backend    # FastAPI + LangGraph
â”œâ”€â”€ Dockerfile.frontend   # Nginx + React SPA
â”œâ”€â”€ Dockerfile.sandbox    # Python sandbox environment
â””â”€â”€ DB-README.md          # Database documentation
```

---

## ðŸ› Troubleshooting

### "Network langgraph-network not found"
```bash
docker network create langgraph-network
```

### Backend can't spawn sandbox containers
Ensure Docker socket is mounted:
```yaml
volumes:
  - /var/run/docker.sock:/var/run/docker.sock
```

### Frontend can't connect to backend
Check CORS in `.env`:
```bash
CORS_ORIGINS=http://localhost,http://localhost:80,http://localhost:5173
```

### Database migration needed
```bash
docker exec lg_urban_backend alembic upgrade head
```

### Reset everything
```bash
docker compose down -v  # WARNING: Deletes all data
docker network create langgraph-network
docker build -f Dockerfile.sandbox -t sandbox:latest .
docker compose up -d
```

---

## ðŸ“š Documentation

- **[DB-README.md](./DB-README.md)** - Database architecture & Alembic guide
- **[PLAN.md](./PLAN.md)** - Implementation plan & design decisions

---

## ðŸ§ª Available Python Libraries in Sandbox

**Data Science:**
- pandas, numpy, scipy, statsmodels
- scikit-learn, scikit-image
- matplotlib, seaborn, plotly

**Geographic:**
- geopandas, shapely, folium, rasterio

**Formats:**
- pyarrow (Parquet/GeoParquet), openpyxl, xlrd

**Utilities:**
- requests, beautifulsoup4, pillow

---

## ðŸ“„ License

MIT

---

## ðŸ™ Credits

Fused from:
- **LG-App-Template** - Chat foundation with PostgreSQL
- **LangGraph-Sandbox** - Sandboxed code execution architecture

Special thanks to the Bologna Open Data initiative for providing rich civic datasets.
