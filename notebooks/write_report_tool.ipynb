{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "326f9c9c",
   "metadata": {},
   "source": [
    "# Implementing the `write_report()` tool and testing it out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c2df0d",
   "metadata": {},
   "source": [
    "## Brainstorming\n",
    "\n",
    "\n",
    "\n",
    "We want the model to be able to produce a report of the analysis performed. \n",
    "\n",
    "What it should do:\n",
    "\n",
    "1. *Get the full chat history in order to see al relevant analysis performed*\n",
    "    \n",
    "    **challenges:** \n",
    "\n",
    "    - If chat gets summarized, previous analysis are blurred out. We need detailed history, but at the same time we cannot input more than a certain number of tokens to the model that produces the analysis. \n",
    "    \n",
    "    **solutions:**\n",
    "\n",
    "    - we need to keep the full chat state somewhere when we summarize. Maybe store it in state. Could be a long `analysis` str, or could be a virtual file in the virtual file system. Then the `write_report()` tool could split the full history in sections in order not to exceed context length.     \n",
    "\n",
    "2. *Collect all sources used - meaning, the list of all datasets analized*\n",
    "    \n",
    "    **challenges:**\n",
    "\n",
    "    - We have to keep track of all used datasets.\n",
    "    \n",
    "    **solutions:**\n",
    "    \n",
    "    - Just add a state var `sources`; it gets filled every time we **select** a dataset with the `select_dataset` tool. The model that writes the report can then cite the source throughout the report, understanding when it was used from chat history.\n",
    "\n",
    "3. *Produce an extensive report (.md format probably)*\n",
    "\n",
    "----\n",
    "\n",
    "> **? Should the report include python code ?**\n",
    ">\n",
    "> It could be useful to include in the report - or somewhere else - all python code written during the analysis. \n",
    "> If could be a section/appendyx in the report, or a separate file that the user can ask to be given. \n",
    "> or simply another state str that gets filled up anytime the code exec runs - then we manually combine it into an appendyx in the report. i Just don't want it to be like 3000 lines at the end of the report. maybe they should be separate files. \n",
    "\n",
    "> *DB Related:* This extra stuff needs to remain visible to the user when he goes back to previous chats - add those in the db \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5999d2d9",
   "metadata": {},
   "source": [
    "## Implementation, pt.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5674ed22",
   "metadata": {},
   "source": [
    "We will now: \n",
    "\n",
    "1. create a new state with the new state vars we need\n",
    "2. give the model a simpler repl tool that can still generate python code and get stdout and stderr - or make it fake\n",
    "3. give the model a fake select ds tool that adds the sources to state var\n",
    "4. create the real write_report() tool (and a nice prompt) for the model to use all the rest. \n",
    "5. make it write to file so we can read it.   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0788e591",
   "metadata": {},
   "source": [
    "### 1. State Vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d32becc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentState\n",
    "from typing import Annotated\n",
    "\n",
    "def merge_dicts(\n",
    "    left: dict[str, str] | None = None,\n",
    "    right: dict[str, str] | None = None\n",
    ") -> dict[str, str]:\n",
    "    \"\"\"Merge two dictionaries. Left takes precedence over right. Used for reports.\"\"\"\n",
    "    if left is None:\n",
    "        left = {}\n",
    "    if right is None:\n",
    "        right = {}\n",
    "    return {**left, **right}\n",
    "\n",
    "def merge_dicts_nested(\n",
    "    left: dict[str, dict[str, str]] | None = None, \n",
    "    right: dict[str, dict[str, str]] | None = None\n",
    ") -> dict[str, dict[str, str]]:\n",
    "    \"\"\"Merge two nested dictionaries. Left takes precedence over right. Used for sources.\"\"\"\n",
    "    if left is None:\n",
    "        left = {}\n",
    "    if right is None:\n",
    "        right = {}\n",
    "    return {**left, **right}\n",
    "\n",
    "def list_add(\n",
    "    left: list[dict[str, str]] | None = None,\n",
    "    right: list[dict[str, str]] | None = None\n",
    ") -> list[dict[str, str]]:\n",
    "    \"\"\"Add a new item to a list. Used for code. No deduplication - running the same code twice is meaningful.\"\"\"\n",
    "    if left is None:\n",
    "        left = []\n",
    "    if right is None:\n",
    "        right = []\n",
    "    \n",
    "    return left + right\n",
    "\n",
    "def str_replace(\n",
    "    left: str | None,\n",
    "    right: str | None\n",
    ") -> str:\n",
    "    \"\"\"Update a string just by replacing it. Reducer needed to initialize when None\"\"\"\n",
    "    if left is None:\n",
    "        return \"\"\n",
    "    else:\n",
    "        return right\n",
    "\n",
    "def bool_replace(\n",
    "    left: bool | None,\n",
    "    right: bool | None\n",
    ") -> bool:\n",
    "    \"\"\"Update a boolean just by replacing it. Reducer needed to initialize when None\"\"\"\n",
    "    if left is None:\n",
    "        return False\n",
    "    else:\n",
    "        return right\n",
    "\n",
    "class MyState(AgentState):\n",
    "    # here we would have also summary and token count\n",
    "    sources : Annotated[dict[str, dict[str, str]], merge_dicts_nested] # key is the dataset id, value is a dict with desc, url\n",
    "    reports: Annotated[dict[str, str], merge_dicts]  # key is the title, value is the content \n",
    "    write_report : Annotated[bool, bool_replace]\n",
    "    last_report_title : Annotated[str, str_replace]\n",
    "    edit_instructions : Annotated[str, str_replace]\n",
    "    code_logs: Annotated[list[dict[str, str]], list_add]  # list of dicts (we need chronologcal order!), each dicts is input and output of a code block (out can be stdout or stderr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a9177e",
   "metadata": {},
   "source": [
    "Will these reducers work well with left + right if they are dicts?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6989407e",
   "metadata": {},
   "source": [
    "### 2. & 3. Fake tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e1fb610",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import tool, ToolRuntime\n",
    "from langchain_core.messages import ToolMessage\n",
    "from langgraph.types import Command\n",
    "\n",
    "\n",
    "@tool\n",
    "def code_exec(\n",
    "    code: Annotated[str, \"The python code to execute to generate your chart.\"],\n",
    "    runtime: ToolRuntime\n",
    ")->Command: \n",
    "    \"\"\"Use this to execute python code.\"\"\"\n",
    "\n",
    "    result = \"\"\"# code executed succesfully\"\"\"  # this would be stdout\n",
    "    code_dict = {\"input\": code, \"output\": result}\n",
    "\n",
    "    return Command(\n",
    "        update = {\n",
    "            \"messages\" : [ToolMessage(content = result, tool_call_id = runtime.tool_call_id)],\n",
    "            \"code_logs\": [code_dict], # wrap in list for reducer\n",
    "        }\n",
    "    )\n",
    "\n",
    "@tool \n",
    "def select_dataset(\n",
    "    dataset_id: str,\n",
    "    runtime: ToolRuntime\n",
    ")->Command:\n",
    "    \"\"\"\n",
    "    Select a dataset from the list of available datasets. Adds it to the list of sources automatically.\n",
    "    \"\"\"\n",
    "\n",
    "    dataset_dict = {dataset_id: {\"desc\": \"dataset test description\", \"url\": \"dataset test url\"}}\n",
    "    return Command(\n",
    "        update = {\n",
    "            \"messages\" : [ToolMessage(content = f\"Selected and loaded dataset {dataset_id}\", tool_call_id = runtime.tool_call_id)],\n",
    "            \"sources\" : dataset_dict\n",
    "        }\n",
    "    )\n",
    "\n",
    "\n",
    "@tool\n",
    "def assign_to_report_writer(\n",
    "    reason: Annotated[str, \"Brief reason why analysis is complete and report should be written\"],\n",
    "    runtime: ToolRuntime\n",
    ") -> Command:\n",
    "    \"\"\"\n",
    "    Assign the task to the report writer when analysis is complete. \n",
    "    Since tool assingment was not working, reverted to state flag + conditional edge\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"***assigning to report writer\")\n",
    "    \n",
    "    return Command(\n",
    "        update={\n",
    "            \"messages\": [ToolMessage(\n",
    "                content=f\"Analysis complete. {reason}. Assigning to report writer.\", \n",
    "                tool_call_id=runtime.tool_call_id\n",
    "            )],\n",
    "            \"write_report\" : True\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5fe0aaf",
   "metadata": {},
   "source": [
    "### 4. & 5. Write report tool\n",
    "\n",
    "We can actually add interruption before the tool is called, so that the user can reject the report writing if not needed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65b7165b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.types import interrupt\n",
    "\n",
    "@tool\n",
    "def write_report(\n",
    "    report_title: Annotated[str, \"The title of the report\"],\n",
    "    report_content: Annotated[str, \"The content of the report\"],\n",
    "    runtime: ToolRuntime\n",
    ")->Command:\n",
    "    \"\"\"\n",
    "    Write a report of the analysis performed.\n",
    "    \"\"\"\n",
    "\n",
    "    state = runtime.state\n",
    "\n",
    "    print(\"***using write_report***\")\n",
    "\n",
    "    # interrupt only if the writer is not editing an existing report\n",
    "    if state[\"edit_instructions\"] == \"\":\n",
    "\n",
    "        print(\"asking for report writing approval\")\n",
    "        response = interrupt(f\"The model has finished its analysis and wants to write a report. To continue, input 'yes'. To reject, input 'no'.\")\n",
    "\n",
    "        if response[\"type\"] == \"accept\":\n",
    "            pass\n",
    "        elif response[\"type\"] == \"reject\":\n",
    "            return Command(goto=\"__end__\")  # end flow\n",
    "        else:\n",
    "            raise ValueError(f\"Invalid response type: {response['type']}\")\n",
    "\n",
    "    report_dict = {report_title: report_content}\n",
    "\n",
    "    # also write to file in dev\n",
    "    with open(\"report.md\", \"w\") as f:\n",
    "        f.write(f\"# {report_title}\\n{report_content}\\n\\n\")\n",
    "        \n",
    "        # append code execution logs\n",
    "        for code_log in state[\"code_logs\"]:\n",
    "            f.write(f\"## Appendyx: code execution\\n\")\n",
    "            f.write(f\"\\n```python\\n{code_log['input']}\\n```\\n\")\n",
    "            f.write(f\"stdout:\\n```bash\\n{code_log['output']}\\n```\\n\")\n",
    "\n",
    "    return Command(\n",
    "        update = {\n",
    "            \"messages\" : [ToolMessage(content=\"Report written\", tool_call_id=runtime.tool_call_id)],\n",
    "            \"reports\" : report_dict,\n",
    "            \"last_report_title\" : report_title,\n",
    "            \"edit_instructions\" : \"\"  # clear if there were any \n",
    "        }\n",
    "    )\n",
    "\n",
    "# probably should make a modify_report() tool that can be used to add to modify an existing report\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "230960bb",
   "metadata": {},
   "source": [
    "How should i make it add sources? first make the report than another pass for sources? A `read_sources` tool?\n",
    "\n",
    "Maybe for the moment we keep it simple and just invoke the agent on messages and sources. He will add sources at the end. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "389100a2",
   "metadata": {},
   "source": [
    "### 6. Create a well rounded prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee915a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "report_prompt = \"\"\"\n",
    "You are an AI assistant that works together with a data analyst colleague.\n",
    "\n",
    "After the data analyst performs an analysis, you will be asked to write a report of the analysis performed.\n",
    "\n",
    "In order to do so, you MUST use your `write_report()` tool. It takes 2 arguments:\n",
    "\n",
    "1. `report_title`: a string with the title of the report\n",
    "2. `report_content`: a string with the content of the report\n",
    "\n",
    "The title and the content MUST be formatted in markdown.\n",
    "\n",
    "For the content, follow these instructions:\n",
    "\n",
    "1. Do not include the title in the content. It will be added automatically.\n",
    "2. Structure the report in subsections, each with a title and a content.\n",
    "3. For each subsection, include the analysis performed in a comprehensive way, covering all the main points, and going into detail when needed.\n",
    "4. At the end of the report, add a section \"Sources\" where you list all the sources used in the analysis.\n",
    "5. NEVER include python code in the report.\n",
    "\n",
    "You may be asked either to write a new report or to revise an existing one. \n",
    "If you revise an existing report, follow the edit instructions that you will be given.\n",
    "\n",
    "In this specific run, the analysis will be short since it is a test, so write the report anyway even if you do not have enough information. Use your `write_report()` tool.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c053de3e",
   "metadata": {},
   "source": [
    "## Implementation, pt.2 - Graph\n",
    "\n",
    "The second part of the implementation reguards the graph structure. We want to have:\n",
    "\n",
    "1. A node that invokes the report writer on messages and sources. \n",
    "2. A *human-edit step*, where the user can edit the report if he wants.\n",
    "\n",
    "> Note: A *human-approval step*, where the user can confirm or deny the report writing, will be in the tool directly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf81a82",
   "metadata": {},
   "source": [
    "### 1. Create the agents (report writer + fake analyst)\n",
    "\n",
    "First let's create our two agents, the fake analyst and the \"almost-real\" report writer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5db715aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyst_prompt = \"\"\"\n",
    "You are an AI assistant that works together with a report writing colleague.\n",
    "\n",
    "You perform analysis on the datasets at your disposal, and when the analysis is finished you route to the report writer in order to write the report.\n",
    "In order to route to the report writer, you MUST use your `assign_to_report_writer` tool. \n",
    "\n",
    "This specific run is a test; you MUST follow these steps:\n",
    "\n",
    "1. Select the datasets \"dataset1\" and \"dataset2\" with the `select_dataset` tool\n",
    "\n",
    "2. Use your `code_exec` tool to execute this code snippet:\n",
    "```python\n",
    "# analysis code\n",
    "import pandas as pd\n",
    "\n",
    "df1 = pd.read_csv(\"dataset1.csv\")\n",
    "df2 = pd.read_csv(\"dataset2.csv\")\n",
    "\n",
    "# plot results\n",
    "plt.figure()\n",
    "plt.plot(df1[\"x\"], df1[\"y\"])\n",
    "plt.plot(df2[\"x\"], df2[\"y\"])\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "3. Route to the report writer agent by using the `assign_to_report_writer` tool.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e296394",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain.agents import create_agent\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "env = load_dotenv()\n",
    "\n",
    "analyst_llm = ChatOpenAI(model=\"gpt-4.1\", temperature=0)\n",
    "report_llm = ChatOpenAI(model=\"gpt-4.1\", temperature=0) # ChatAnthropic(model=\"claude-sonnet-4-5\")\n",
    "\n",
    "# report writer agent\n",
    "report_agent = create_agent(\n",
    "    model=report_llm,\n",
    "    system_prompt=report_prompt,\n",
    "    tools=[write_report],\n",
    "    state_schema=MyState\n",
    ")\n",
    "\n",
    "# analyst agent\n",
    "analyst_agent = create_agent(\n",
    "    model=analyst_llm,\n",
    "    system_prompt=analyst_prompt,\n",
    "    tools=[code_exec, select_dataset, assign_to_report_writer], \n",
    "    state_schema=MyState\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ab6a588",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "from langgraph.graph import StateGraph, START\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langgraph.types import interrupt\n",
    "\n",
    "\n",
    "def make_graph(checkpointer):\n",
    "    \"\"\"\n",
    "    Defines nodes and edges, builds and compiles the graph\n",
    "    \"\"\"\n",
    "\n",
    "    # trying workaround; since we cannot nest commands, we use state to flag\n",
    "    def get_next_node(state: MyState):\n",
    "        \n",
    "        print(f\"***state['write_report']: {state['write_report']}\")\n",
    "        \n",
    "        if state[\"write_report\"] == True:\n",
    "            print(\"***routing to report_writer\")\n",
    "            return \"report_writer\"\n",
    "    \n",
    "        return \"__end__\"\n",
    "\n",
    "    async def analyst_node(state: MyState,\n",
    "    ) -> Command[Literal[\"report_writer\", \"__end__\"]]:  \n",
    "        \"\"\"\n",
    "        Invokes the analyst agent\n",
    "        \"\"\"\n",
    "        result = await analyst_agent.ainvoke(state)\n",
    "        last_msg = result[\"messages\"][-1]\n",
    "\n",
    "        # routing happens here\n",
    "        goto = get_next_node(result)\n",
    "\n",
    "        print(f\"***goto: {goto}\")\n",
    "\n",
    "        return Command(\n",
    "            update = {\n",
    "                \"messages\" : [last_msg],\n",
    "                \"code_logs\" : result.get(\"code_logs\", []),\n",
    "                \"sources\" : result.get(\"sources\", {}),\n",
    "                \"write_report\" : result.get(\"write_report\", False)  # analyst may set this to True with the assign_to_report_writer tool\n",
    "            },\n",
    "            goto=goto\n",
    "        )\n",
    "\n",
    "    async def write_report_node(state: MyState,\n",
    "    ) -> Command[Literal[\"human_approval\"]]:\n",
    "        \"\"\"\n",
    "        Invokes the report writer agent\n",
    "        \"\"\"\n",
    "\n",
    "        if state[\"edit_instructions\"] != \"\": # edits: revise existing report\n",
    "            msg = f\"Revise the report based on the following instructions: {state['edit_instructions']}\"\n",
    "            messages = state[\"messages\"] + [HumanMessage(content=msg)]\n",
    "        else: # no edits: write a new report\n",
    "            msg = \"Write a new report based on the analysis performed and the sources used.\"\n",
    "            messages = state[\"messages\"] + [HumanMessage(content=msg)]\n",
    "\n",
    "        # invoke on full state but use messages with new sys msg\n",
    "        result = await report_agent.ainvoke({**state, \"messages\": messages})\n",
    "        last_msg = result[\"messages\"][-1]\n",
    "\n",
    "        return Command(\n",
    "            update = {  # propagate possible updates\n",
    "                \"messages\": [last_msg],\n",
    "                \"reports\": result.get(\"reports\", {}),  # Tool updated this\n",
    "                \"last_report_title\": result.get(\"last_report_title\"),  # Tool updated this\n",
    "                \"edit_instructions\": \"\"  # clear edit instructions (if there were any, report writer already used them)\n",
    "            },\n",
    "            goto=\"human_approval\"\n",
    "        )\n",
    "\n",
    "    async def human_approval_node(state: MyState,\n",
    "    ) -> Command[Literal[\"report_writer\", \"__end__\"]]:\n",
    "        \"\"\"\n",
    "        Human approval step\n",
    "        \"\"\"\n",
    "        # Safety check\n",
    "        if not state[\"last_report_title\"] or state[\"last_report_title\"] not in state[\"reports\"]:\n",
    "            print(\"Error: No report has been written yet!\")\n",
    "            print(state[\"reports\"])\n",
    "            print(state[\"last_report_title\"])\n",
    "            return Command(goto=\"__end__\")\n",
    "\n",
    "        human_input = interrupt({\n",
    "            \"question\": \"The report has been generated. If you approve the report, input 'yes' - once approved, you can manually edit it. If instead you want the model to edit it, input your desired changes.\",\n",
    "            \"report\": state[\"reports\"][state[\"last_report_title\"]]\n",
    "        })\n",
    "\n",
    "        if human_input[\"type\"] == \"accept\":\n",
    "            return Command(goto=\"__end__\")\n",
    "        elif human_input[\"type\"] == \"edit\":\n",
    "            return Command(goto=\"report_writer\", update={\"edit_instructions\": human_input[\"edit_instructions\"]})\n",
    "\n",
    "\n",
    "    builder = StateGraph(MyState)\n",
    "    builder.add_node(\"analyst\", analyst_node)\n",
    "    builder.add_node(\"report_writer\", write_report_node)\n",
    "    builder.add_node(\"human_approval\", human_approval_node)\n",
    "    builder.add_edge(START, \"analyst\")\n",
    "    return builder.compile(checkpointer=checkpointer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da85732d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from IPython.display import Image, display\n",
    "\n",
    "checkpointer = InMemorySaver()\n",
    "\n",
    "graph = make_graph(checkpointer)\n",
    "\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "357add65",
   "metadata": {},
   "source": [
    "## Test it out\n",
    "\n",
    "We need to be careful with the `Command(resume)` in graph stream, because of the interrupts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc3a68d",
   "metadata": {},
   "source": [
    "Also, I need to test the approval/edit of the report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cbc2c7ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***assigning to report writer\n",
      "***state['write_report']: True\n",
      "***routing to report_writer\n",
      "***goto: report_writer\n",
      "{'analyst': {'messages': [AIMessage(content='The analysis of dataset1 and dataset2 is complete, including data loading and plotting. The results are now ready for the report writer to prepare the report.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 32, 'prompt_tokens': 630, 'total_tokens': 662, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4.1-2025-04-14', 'system_fingerprint': 'fp_422e2d36a8', 'id': 'chatcmpl-CUGjPyrpkBj6Or3J50O04JxNgmu4J', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--f33990f6-31d9-4592-8650-e187f5d59fcc-0', usage_metadata={'input_tokens': 630, 'output_tokens': 32, 'total_tokens': 662, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})], 'code_logs': [{'input': '# analysis code\\nimport pandas as pd\\nimport matplotlib.pyplot as plt\\n\\ndf1 = pd.read_csv(\"dataset1.csv\")\\ndf2 = pd.read_csv(\"dataset2.csv\")\\n\\n# plot results\\nplt.figure()\\nplt.plot(df1[\"x\"], df1[\"y\"])\\nplt.plot(df2[\"x\"], df2[\"y\"])\\nplt.show()\\n', 'output': '# code executed succesfully'}], 'sources': {'dataset1': {'desc': 'dataset test description', 'url': 'dataset test url'}, 'dataset2': {'desc': 'dataset test description', 'url': 'dataset test url'}}, 'write_report': True}}\n",
      "***using write_report***\n",
      "asking for report writing approval\n",
      "{'__interrupt__': (Interrupt(value=\"The model has finished its analysis and wants to write a report. To continue, input 'yes'. To reject, input 'no'.\", id='6bb764dc6ae18cde14e2bb12e4a070f0'),)}\n"
     ]
    }
   ],
   "source": [
    "user_text = \"Perform analysis on dataset1 and dataset2, then write a report.\"\n",
    "state = {\"messages\": [{\"role\": \"user\", \"content\": user_text}]}\n",
    "config = {\"configurable\": {\"thread_id\": \"test-123\"}}\n",
    "\n",
    "\n",
    "async for chunk in graph.astream(state, config):\n",
    "    print(chunk)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ab5b8bed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "messages [HumanMessage(content='Perform analysis on dataset1 and dataset2, then write a report.', additional_kwargs={}, response_metadata={}, id='d0be7b40-d055-4a30-9f38-7415dc24906c'), AIMessage(content='The analysis of dataset1 and dataset2 is complete, including data loading and plotting. The results are now ready for the report writer to prepare the report.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 32, 'prompt_tokens': 630, 'total_tokens': 662, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4.1-2025-04-14', 'system_fingerprint': 'fp_422e2d36a8', 'id': 'chatcmpl-CUGjPyrpkBj6Or3J50O04JxNgmu4J', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--f33990f6-31d9-4592-8650-e187f5d59fcc-0', usage_metadata={'input_tokens': 630, 'output_tokens': 32, 'total_tokens': 662, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]\n",
      "sources {'dataset1': {'desc': 'dataset test description', 'url': 'dataset test url'}, 'dataset2': {'desc': 'dataset test description', 'url': 'dataset test url'}}\n",
      "reports {}\n",
      "write_report True\n",
      "last_report_title \n",
      "edit_instructions \n",
      "code_logs [{'input': '# analysis code\\nimport pandas as pd\\nimport matplotlib.pyplot as plt\\n\\ndf1 = pd.read_csv(\"dataset1.csv\")\\ndf2 = pd.read_csv(\"dataset2.csv\")\\n\\n# plot results\\nplt.figure()\\nplt.plot(df1[\"x\"], df1[\"y\"])\\nplt.plot(df2[\"x\"], df2[\"y\"])\\nplt.show()\\n', 'output': '# code executed succesfully'}]\n"
     ]
    }
   ],
   "source": [
    "state = graph.get_state(config)\n",
    "for key, value in state.values.items():\n",
    "    print(key, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6c713903",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***using write_report***\n",
      "asking for report writing approval\n",
      "{'report_writer': {'messages': [AIMessage(content='Here is the report based on the analysis performed:\\n\\n# Comparative Analysis of Dataset1 and Dataset2\\n\\n## Introduction\\n\\nThis report presents a comparative analysis of two datasets, referred to as dataset1 and dataset2. The analysis includes an overview of the data, key findings from exploratory data analysis, and a summary of the main insights derived from the comparison.\\n\\n## Data Overview\\n\\nBoth dataset1 and dataset2 were loaded and inspected to understand their structure and content. The datasets were checked for completeness, consistency, and any notable patterns or anomalies. Initial exploration included examining the number of records, key variables, and basic descriptive statistics.\\n\\n## Exploratory Data Analysis\\n\\nVisualizations and summary statistics were generated for both datasets. This included plotting distributions of key variables and comparing central tendencies (such as mean and median) and variability (such as standard deviation) between the two datasets. Any significant differences or similarities observed in the data distributions were noted.\\n\\n## Key Findings\\n\\n- Dataset1 and dataset2 share some structural similarities but also exhibit distinct characteristics in their variable distributions.\\n- The analysis highlighted areas where the datasets align closely, as well as variables where notable differences exist.\\n- No major data quality issues were detected during the initial inspection.\\n\\n## Conclusion\\n\\nThe comparative analysis of dataset1 and dataset2 provides a foundation for further, more detailed investigation. The initial findings suggest both commonalities and differences that may warrant deeper exploration depending on the specific research or business questions at hand.\\n\\n## Sources\\n\\n- Internal data sources: dataset1 and dataset2\\n- Data analysis performed by the data analyst team', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 314, 'prompt_tokens': 758, 'total_tokens': 1072, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4.1-2025-04-14', 'system_fingerprint': 'fp_422e2d36a8', 'id': 'chatcmpl-CUGjZwvKpcZAjxV3PScPDK0DvrXKb', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--1aad21ce-d517-4fb3-be28-2060b9713333-0', usage_metadata={'input_tokens': 758, 'output_tokens': 314, 'total_tokens': 1072, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})], 'reports': {'Comparative Analysis of Dataset1 and Dataset2': '## Introduction\\n\\nThis report presents a comparative analysis of two datasets, referred to as dataset1 and dataset2. The analysis includes an overview of the data, key findings from exploratory data analysis, and a summary of the main insights derived from the comparison.\\n\\n## Data Overview\\n\\nBoth dataset1 and dataset2 were loaded and inspected to understand their structure and content. The datasets were checked for completeness, consistency, and any notable patterns or anomalies. Initial exploration included examining the number of records, key variables, and basic descriptive statistics.\\n\\n## Exploratory Data Analysis\\n\\nVisualizations and summary statistics were generated for both datasets. This included plotting distributions of key variables and comparing central tendencies (such as mean and median) and variability (such as standard deviation) between the two datasets. Any significant differences or similarities observed in the data distributions were noted.\\n\\n## Key Findings\\n\\n- Dataset1 and dataset2 share some structural similarities but also exhibit distinct characteristics in their variable distributions.\\n- The analysis highlighted areas where the datasets align closely, as well as variables where notable differences exist.\\n- No major data quality issues were detected during the initial inspection.\\n\\n## Conclusion\\n\\nThe comparative analysis of dataset1 and dataset2 provides a foundation for further, more detailed investigation. The initial findings suggest both commonalities and differences that may warrant deeper exploration depending on the specific research or business questions at hand.\\n\\n## Sources\\n\\n- Internal data sources: dataset1 and dataset2\\n- Data analysis performed by the data analyst team\\n'}, 'last_report_title': 'Comparative Analysis of Dataset1 and Dataset2', 'edit_instructions': ''}}\n",
      "{'__interrupt__': (Interrupt(value={'question': \"The report has been generated. If you approve the report, input 'yes' - once approved, you can manually edit it. If instead you want the model to edit it, input your desired changes.\", 'report': '## Introduction\\n\\nThis report presents a comparative analysis of two datasets, referred to as dataset1 and dataset2. The analysis includes an overview of the data, key findings from exploratory data analysis, and a summary of the main insights derived from the comparison.\\n\\n## Data Overview\\n\\nBoth dataset1 and dataset2 were loaded and inspected to understand their structure and content. The datasets were checked for completeness, consistency, and any notable patterns or anomalies. Initial exploration included examining the number of records, key variables, and basic descriptive statistics.\\n\\n## Exploratory Data Analysis\\n\\nVisualizations and summary statistics were generated for both datasets. This included plotting distributions of key variables and comparing central tendencies (such as mean and median) and variability (such as standard deviation) between the two datasets. Any significant differences or similarities observed in the data distributions were noted.\\n\\n## Key Findings\\n\\n- Dataset1 and dataset2 share some structural similarities but also exhibit distinct characteristics in their variable distributions.\\n- The analysis highlighted areas where the datasets align closely, as well as variables where notable differences exist.\\n- No major data quality issues were detected during the initial inspection.\\n\\n## Conclusion\\n\\nThe comparative analysis of dataset1 and dataset2 provides a foundation for further, more detailed investigation. The initial findings suggest both commonalities and differences that may warrant deeper exploration depending on the specific research or business questions at hand.\\n\\n## Sources\\n\\n- Internal data sources: dataset1 and dataset2\\n- Data analysis performed by the data analyst team\\n'}, id='ed4f4323ca1a86a04c5d525120309bae'),)}\n"
     ]
    }
   ],
   "source": [
    "user_msg = \"yes\"\n",
    "if user_msg == \"yes\":\n",
    "    resume_value = {'type': 'accept'}\n",
    "else:\n",
    "    resume_value = {'type': 'reject'}\n",
    "\n",
    "async for chunk in graph.astream(Command(resume=resume_value), config):\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fee49a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = graph.get_state(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d2ea5a7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "messages [HumanMessage(content='Perform analysis on dataset1 and dataset2, then write a report.', additional_kwargs={}, response_metadata={}, id='d0be7b40-d055-4a30-9f38-7415dc24906c'), AIMessage(content='The analysis of dataset1 and dataset2 is complete, including data loading and plotting. The results are now ready for the report writer to prepare the report.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 32, 'prompt_tokens': 630, 'total_tokens': 662, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4.1-2025-04-14', 'system_fingerprint': 'fp_422e2d36a8', 'id': 'chatcmpl-CUGjPyrpkBj6Or3J50O04JxNgmu4J', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--f33990f6-31d9-4592-8650-e187f5d59fcc-0', usage_metadata={'input_tokens': 630, 'output_tokens': 32, 'total_tokens': 662, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), AIMessage(content='Here is the report based on the analysis performed:\\n\\n# Comparative Analysis of Dataset1 and Dataset2\\n\\n## Introduction\\n\\nThis report presents a comparative analysis of two datasets, referred to as dataset1 and dataset2. The analysis includes an overview of the data, key findings from exploratory data analysis, and a summary of the main insights derived from the comparison.\\n\\n## Data Overview\\n\\nBoth dataset1 and dataset2 were loaded and inspected to understand their structure and content. The datasets were checked for completeness, consistency, and any notable patterns or anomalies. Initial exploration included examining the number of records, key variables, and basic descriptive statistics.\\n\\n## Exploratory Data Analysis\\n\\nVisualizations and summary statistics were generated for both datasets. This included plotting distributions of key variables and comparing central tendencies (such as mean and median) and variability (such as standard deviation) between the two datasets. Any significant differences or similarities observed in the data distributions were noted.\\n\\n## Key Findings\\n\\n- Dataset1 and dataset2 share some structural similarities but also exhibit distinct characteristics in their variable distributions.\\n- The analysis highlighted areas where the datasets align closely, as well as variables where notable differences exist.\\n- No major data quality issues were detected during the initial inspection.\\n\\n## Conclusion\\n\\nThe comparative analysis of dataset1 and dataset2 provides a foundation for further, more detailed investigation. The initial findings suggest both commonalities and differences that may warrant deeper exploration depending on the specific research or business questions at hand.\\n\\n## Sources\\n\\n- Internal data sources: dataset1 and dataset2\\n- Data analysis performed by the data analyst team', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 314, 'prompt_tokens': 758, 'total_tokens': 1072, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4.1-2025-04-14', 'system_fingerprint': 'fp_422e2d36a8', 'id': 'chatcmpl-CUGjZwvKpcZAjxV3PScPDK0DvrXKb', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--1aad21ce-d517-4fb3-be28-2060b9713333-0', usage_metadata={'input_tokens': 758, 'output_tokens': 314, 'total_tokens': 1072, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]\n",
      "sources {'dataset1': {'desc': 'dataset test description', 'url': 'dataset test url'}, 'dataset2': {'desc': 'dataset test description', 'url': 'dataset test url'}}\n",
      "reports {'Comparative Analysis of Dataset1 and Dataset2': '## Introduction\\n\\nThis report presents a comparative analysis of two datasets, referred to as dataset1 and dataset2. The analysis includes an overview of the data, key findings from exploratory data analysis, and a summary of the main insights derived from the comparison.\\n\\n## Data Overview\\n\\nBoth dataset1 and dataset2 were loaded and inspected to understand their structure and content. The datasets were checked for completeness, consistency, and any notable patterns or anomalies. Initial exploration included examining the number of records, key variables, and basic descriptive statistics.\\n\\n## Exploratory Data Analysis\\n\\nVisualizations and summary statistics were generated for both datasets. This included plotting distributions of key variables and comparing central tendencies (such as mean and median) and variability (such as standard deviation) between the two datasets. Any significant differences or similarities observed in the data distributions were noted.\\n\\n## Key Findings\\n\\n- Dataset1 and dataset2 share some structural similarities but also exhibit distinct characteristics in their variable distributions.\\n- The analysis highlighted areas where the datasets align closely, as well as variables where notable differences exist.\\n- No major data quality issues were detected during the initial inspection.\\n\\n## Conclusion\\n\\nThe comparative analysis of dataset1 and dataset2 provides a foundation for further, more detailed investigation. The initial findings suggest both commonalities and differences that may warrant deeper exploration depending on the specific research or business questions at hand.\\n\\n## Sources\\n\\n- Internal data sources: dataset1 and dataset2\\n- Data analysis performed by the data analyst team\\n'}\n",
      "write_report True\n",
      "last_report_title Comparative Analysis of Dataset1 and Dataset2\n",
      "edit_instructions \n",
      "code_logs [{'input': '# analysis code\\nimport pandas as pd\\nimport matplotlib.pyplot as plt\\n\\ndf1 = pd.read_csv(\"dataset1.csv\")\\ndf2 = pd.read_csv(\"dataset2.csv\")\\n\\n# plot results\\nplt.figure()\\nplt.plot(df1[\"x\"], df1[\"y\"])\\nplt.plot(df2[\"x\"], df2[\"y\"])\\nplt.show()\\n', 'output': '# code executed succesfully'}]\n"
     ]
    }
   ],
   "source": [
    "for key, value in state.values.items():\n",
    "    print(key, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0b6fe417",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'human_approval': None}\n"
     ]
    }
   ],
   "source": [
    "user_msg = \"accept\"\n",
    "if user_msg == \"accept\":\n",
    "    resume_value = {'type': 'accept'}\n",
    "else:\n",
    "    resume_value = {'type': 'edit', 'edit_instructions': 'Make it less detailed'}\n",
    "\n",
    "async for chunk in graph.astream(Command(resume=resume_value), config):\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "346b7c48",
   "metadata": {},
   "source": [
    "### Note\n",
    "\n",
    "You need to propagate state updates if a tool uses Command and then you invoke in a node.\n",
    "\n",
    "How it works:\n",
    "Tool returns Command(update={...})  Updates are applied to the agent's internal state\n",
    "Agent returns result  Contains the full updated state after all tools run\n",
    "Your node returns Command(update={...})  Only what you specify here gets propagated to the graph's state\n",
    "\n",
    "The agent result is self-contained - it has the full state after tools ran, but it doesn't automatically merge back. You have to explicitly pass it through."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb5d0466",
   "metadata": {},
   "source": [
    "## Migrations\n",
    "\n",
    "We have the obvious migrations suggested in v1 of changing imports to `langchain.agents`, but a not very discussed migration is the use of `ToolRuntime` which is now a unique object condensing `InjectedState`, `InjectedToolCallId` etc.\n",
    "\n",
    "now it works as intended.\n",
    "\n",
    ">**Note:** we used a workaround in order to be able to route to the report writer in a clean way. I wanted to use a Command, but I have to use Command in the analyst node as well, and nested Commands are nasty af (the tool routes to the agent, but the updates have not been propagated yet..maybe could solve it by propagating the full state in the tool Command?). So in the end I created a tool that just updates a flag in state. The goto then checks that flag.   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langgraph-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
